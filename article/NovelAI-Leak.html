<!DOCTYPE html><html><head><script>navigator.serviceWorker&&navigator.serviceWorker.register("/sw.js?v=2822638e0b").then(e=>{if(!localStorage.getItem("installSW")){localStorage.setItem("installSW",!0);const t=setInterval(()=>{"activated"===e.active.state&&(clearInterval(t),fetch(window.location.href).then(e=>e.text()).then(e=>{document.open(),document.write(e),document.close()}))},100)}}).catch(console.log)</script><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta http-equiv="content-language" content="zh-CN"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0"><title>NovelAI 官方前后端部署教程 | 屑荧の小站</title><meta name="author" content="Lumine'blog"><meta name="copyright" content="Lumine'blog"><link rel="shortcut icon" href="https://static.lumine233.ml/Pic/avatar.webp"><meta name="keywords" content="AI"><meta name="description" content="NovelAI近期泄露 Webui版本的效果并没有网络版的好 但是Docker版的效果基本复刻了网络版NovelAI的效果 (对于原始教程重新梳理和排版"><meta property="og:type" content="article"><meta property="og:title" content="NovelAI 官方前后端部署教程"><meta property="og:url" content="https://blog.lumine233.ml/article/NovelAI-Leak.html"><meta property="og:site_name" content="屑荧の小站"><meta property="og:description" content="NovelAI近期泄露 Webui版本的效果并没有网络版的好 但是Docker版的效果基本复刻了网络版NovelAI的效果 (对于原始教程重新梳理和排版"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://static.lumine233.ml/Pic/avatar.webp"><meta property="article:published_time" content="2022-10-09T05:45:00.000Z"><meta property="article:modified_time" content="2022-10-11T15:23:16.000Z"><meta property="article:author" content="Lumine'blog"><meta property="article:tag" content="AI"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://static.lumine233.ml/Pic/avatar.webp"><link href="/third-party/fontawesome-free/css/all.min.css?v=3f5565600b" rel="stylesheet"><link href="/css/main.css?v=77884920af" rel="stylesheet"><script src="/js/utlis.js?v=a73b387a6f"></script><script>!function(){var e=mengd.$query("html");"true"===localStorage.isDark?e.setAttribute("theme","dark"):e.removeAttribute("theme")}()</script><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml?v=426cb0ace5" title="屑荧の小站" type="application/atom+xml"><link rel="alternate" href="/rss.xml?v=9c73fc8151" title="屑荧の小站" type="application/rss+xml"></head><body><script>var $config={CDN:{fancyboxJs:"/third-party/js/fancybox.js?v=881dd0c646",fancyboxCss:"/third-party/css/fancybox.css?v=25e637f333"},searchFile:"/search.json?v=e844149e27",codeBlockExpand:{enable:!0,height:400,scrollTop:200}}</script><div id="body-wrap"><nav id="nav-wrap"><div class="navbar"><div class="bar"><a href="/" class="title">屑荧の小站</a> <i class="fas fa-search search-btn"></i><ul class="menu"><li><a href="/">首页</a></li><li><a class="menu-child-hover" href="javascript:void(0);">找文章</a><ul class="menu-child"><li><a href="/tags">标签</a></li><li><a href="/categories">分类</a></li><li><a href="/archives">归档</a></li></ul></li><li><a href="/link">友情链接</a></li><li><a href="/about">关于我</a></li></ul><i class="fas fa-bars open-nav"></i></div></div><div id="mobile-nav"><ul><li><a href="/">首页</a></li><li><a href="/tags">标签</a></li><li><a href="/categories">分类</a></li><li><a href="/archives">归档</a></li><li><a href="/link">友情链接</a></li><li><a href="/about">关于我</a></li></ul></div></nav><header id="header"><div class="header-author"><a href="/" class="author"><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Pic/avatar.webp" alt="Lumine'blog" class="author-avatar"><div class="author-name">Lumine'blog</div></a></div><div class="header-description"><p>世界...遗忘我</p><div class="header-icon"><a href="mailto:Lumien@jiaran.tk" rel="external nofollow noopener noreferrer" target="_blank"><i class="fa fa-envelope"></i></a> <a href="/rss.xml"><i class="fa fa-rss"></i></a></div></div></header><main id="main"><article id="post"><div class="post-info"><div class="post-title"><h1>NovelAI 官方前后端部署教程</h1></div><div class="post-meta"><div class="post-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i> <span class="post-meta-label">发表于 2022-10-09 | </span><i class="fas fa-history fa-fw post-meta-icon"></i> <span class="post-meta-label">更新于 2022-10-11</span></div><div class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i> <span class="post-meta-label">总字数:</span> <span class="word-count">2.4k | </span><i class="far fa-clock fa-fw post-meta-icon"></i> <span class="post-meta-label">阅读时长:</span> <span>11分钟</span> | <i class="far fa-eye fa-fw post-meta-icon"></i> <span class="post-meta-label">阅读量:</span> <span id="twikoo_visitors">0</span></div></div></div><div class="post-obsolete display-none" style="color:#d4b82a;background:#fcf9e1;border-left:5px solid #ffd818;border-right:5px solid #ffd818" limit_day="30" created="2022-10-09" updated="2022-10-11"><strong>文章时效性提醒:&nbsp;</strong>本文写作于 ${created} 天前，最后修订于 ${updated} 天前，其中的信息可能已经有所发展或者不再适用于现阶段。</div><div class="post-content"><blockquote><p>10-11 更新：显存占用问题可以通过指定 Fp16 计算解决，16G 显存就足够运行完整模型，77Prompt 长度限制通过增加 - e CLIP_CONTEXTS=3 解决，Docker 的启动指令已经更新。</p><p>10-11 更新 @LyanOrz 提供的 Colab 白嫖跑官方前后端</p><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://colab.research.google.com/drive/1_Ma71L6uGbtt6UQyA3FjqW2lcZ5Bjck-">https://colab.research.google.com/drive/1_Ma71L6uGbtt6UQyA3FjqW2lcZ5Bjck-</a></p></blockquote><blockquote><p>一些碎碎念</p><p>其实我感觉自己用的话部署整套 UI + 后端挺麻烦的，毕竟前端只是帮你发了个请求，后端也只是把请求改了个样子发给实际处理的 Api，直接部署 Api 调用 Api 结果是一样的，还方便白嫖。</p><p>可以参考 @LyanOrz 大佬提供的用 Colab 白嫖部署的方法，直接嫖一个后端出来，显卡都省了岂不美哉.jpg</p><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://colab.research.google.com/drive/1X-62QjZJpZ5Ewo3w6xr9D23Tu90udvQI">https://colab.research.google.com/drive/1X-62QjZJpZ5Ewo3w6xr9D23Tu90udvQI</a></p><p>或者使用 Stable-Diffusion Webui 替换模型的 Webui，也是白嫖 Colab</p><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://colab.research.google.com/drive/1zuK0u8UW8IKMEvVNz7lU34Qph_gS14XD">https://colab.research.google.com/drive/1zuK0u8UW8IKMEvVNz7lU34Qph_gS14XD</a></p><p>其他的吐槽</p><p>原版这全套莫名其妙的极其能吃显存，吃完还不释放（见文末尾），如果有大佬优化一下最好了。</p><p>又更新：</p><p>看起来全尺寸的 7G 模型就是特别能吃显存，建议显存低于 24G 的就不要尝试使用官方版本前后端了，铁定爆（</p><p>目前来看如果准备使用官方前后端还想玩 img2img 的话。。。可能需要 32G + 的显存，建议购买 V100S 或者 A6000 或者 A100（跑</p></blockquote><blockquote><p><strong>还没写完文章就有的更新：</strong></p><p><strong>已经有大佬把官方前端后端单独提出来了，没必要折腾下面那么多完整的部署，直接下载运行就好了，默认使用的是 4G 大的模型，理论上替换成 7G 那个模型就是跟官方一样的效果。</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;magnet:?xt=urn:btih:4a4b483d4a5840b6e1fee6b0ca1582c979434e4d&amp;dn=naifu&amp;tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce</span><br></pre></td></tr></table></figure></blockquote><h3 id="1-准备"><a href="#1-准备" class="headerlink" title="1. 准备"></a>1. 准备</h3><h4 id="硬件需求："><a href="#硬件需求：" class="headerlink" title="硬件需求："></a>硬件需求：</h4><ul><li><p>一台拥有一张至少有 24G 显存(单后端至少11G)的 NVIDIA GPU 的 linux 系统的 x86 设备。</p></li><li><p>软件需求：</p></li><li><p>NVIDIA 驱动 (CUDA 11.6 Toolkit)</p></li><li><p>Docker 19+</p></li><li><p>Nvidia-Container-Toolkit</p></li></ul><h3 id="2-安装-Docker"><a href="#2-安装-Docker" class="headerlink" title="2. 安装 Docker"></a>2. 安装 Docker</h3><p>该命令国内访问较慢，可以查国内镜像安装</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -fsSL https://get.docker.com | bash</span><br></pre></td></tr></table></figure><h3 id="3-安装-Nvidia-Container-Toolkit"><a href="#3-安装-Nvidia-Container-Toolkit" class="headerlink" title="3. 安装 Nvidia-Container-Toolkit"></a>3. 安装 Nvidia-Container-Toolkit</h3><h5 id="Ubuntu-Debian："><a href="#Ubuntu-Debian：" class="headerlink" title="Ubuntu, Debian："></a>Ubuntu, Debian：</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">distribution=$(. /etc/os-release;echo $ID$VERSION_ID)</span><br><span class="line"></span><br><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -</span><br><span class="line"></span><br><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list</span><br><span class="line"></span><br><span class="line">sudo apt-get update &amp;&amp; sudo apt-get install -y nvidia-container-toolkit</span><br><span class="line"></span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure><h5 id="CentOS-x2F-RHEL"><a href="#CentOS-x2F-RHEL" class="headerlink" title="CentOS/RHEL"></a>CentOS/RHEL</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">distribution=$(. /etc/os-release;echo $ID$VERSION_ID)</span><br><span class="line"></span><br><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | sudo tee /etc/yum.repos.d/nvidia-docker.repo</span><br><span class="line"></span><br><span class="line">sudo yum install -y nvidia-container-toolkit</span><br><span class="line"></span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure><h3 id="4-安装显卡驱动"><a href="#4-安装显卡驱动" class="headerlink" title="4. 安装显卡驱动"></a>4. 安装显卡驱动</h3><p>略</p><h3 id="5-确认显卡驱动已经安装好-并且nvidia-smi可以看到显卡"><a href="#5-确认显卡驱动已经安装好-并且nvidia-smi可以看到显卡" class="headerlink" title="5. 确认显卡驱动已经安装好,并且nvidia-smi可以看到显卡"></a>5. 确认显卡驱动已经安装好,并且nvidia-smi可以看到显卡</h3><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/9/9e487ee0e864d7a45e7b58383bc84a30.png" alt="nvidia-smi"></p><h3 id="6-确认-Nvidia-Container-Toolkit-安装成功"><a href="#6-确认-Nvidia-Container-Toolkit-安装成功" class="headerlink" title="6. 确认 Nvidia-Container-Toolkit 安装成功"></a>6. 确认 Nvidia-Container-Toolkit 安装成功</h3><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/9/3250490306532386bf195e5c25696f6b.png" alt="nvidia-container-toolkit"></p><h3 id="7-下载-NovelAI-模型相关文件"><a href="#7-下载-NovelAI-模型相关文件" class="headerlink" title="7. 下载 NovelAI 模型相关文件"></a>7. 下载 NovelAI 模型相关文件</h3><p><a target="_blank" rel="noopener" href="https://pan.lumine233.ml/d/Lumine/NovelAI-Leak/Models/novelai.tar.gz">https://pan.lumine233.ml/d/Lumine/NovelAI-Leak/Models/novelai.tar.gz</a></p><h3 id="8-解压-NovelAI-模型相关文件"><a href="#8-解压-NovelAI-模型相关文件" class="headerlink" title="8. 解压 NovelAI 模型相关文件"></a>8. 解压 NovelAI 模型相关文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf novelai.tar.gz</span><br></pre></td></tr></table></figure><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/9/92ac2702a33d6707009a710dc0b05b1e.png" alt="解压模型文件"></p><h3 id="9-下载-Docker-镜像相关文件"><a href="#9-下载-Docker-镜像相关文件" class="headerlink" title="9. 下载 Docker 镜像相关文件"></a>9. 下载 Docker 镜像相关文件</h3><p><a target="_blank" rel="noopener" href="https://pan.lumine233.ml/d/Lumine/NovelAI-Leak/Back-End/novelaidocker.tar">https://pan.lumine233.ml/d/Lumine/NovelAI-Leak/Back-End/novelaidocker.tar</a></p><h3 id="10-导入-Docker-镜像"><a href="#10-导入-Docker-镜像" class="headerlink" title="10. 导入 Docker 镜像"></a>10. 导入 Docker 镜像</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker load -i novelaidocker.tar</span><br></pre></td></tr></table></figure><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/9/e9af4345a4449f52bba53215e03ab962.png" alt="导入Docker镜像"></p><details><summary>继续部署单后端版本</summary><p></p><h4 id="10-1-运行-Docker"><a href="#10-1-运行-Docker" class="headerlink" title="10.1 运行 Docker"></a>10.1 运行 Docker</h4><blockquote><p>如果希望包含 nsfw 内容，则把</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- e MODEL_PATH="/root/stableckpt/animesfw-latest"</span><br></pre></td></tr></table></figure><p>改成</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-e MODEL_PATH="/root/stableckpt/animefull-latest"</span><br></pre></td></tr></table></figure></blockquote><blockquote><p>解压的 novelai 位置替换为你实际解压 NovelAI 模型相关文件出来的 novelai 文件夹的位置，如 /root/novelai</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --gpus all -d -p 80:80 -v 解压的 NovelAI 位置:/root -e  DTYPE="float32" -e AMP="1" -e MODEL="stable-diffusion" -e DEV="True" -e  MODEL_PATH="/root/stableckpt/animesfw-latest" -e  MODULE_PATH="/root/stableckpt/modules" -e  TRANSFORMERS_CACHE="/root/transformer_cache" -e SENTRY_URL=""-e  ENABLE_EMA="1"-e VAE_PATH="/root/stableckpt/animevae.pt"-e  BASEDFORMER="1"-e PENULTIMATE="1" novelai:latest gunicorn main:app  --workers 1 --worker-class uvicorn.workers.UvicornWorker --bind  0.0.0.0:80</span><br></pre></td></tr></table></figure><h4 id="10-2-查看容器状态"><a href="#10-2-查看容器状态" class="headerlink" title="10.2 查看容器状态"></a>10.2 查看容器状态</h4><p>查询出容器 ID</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker ps</span><br></pre></td></tr></table></figure><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/9/f89e89fcc483ddfede837baf474fad3f.png" alt="docker ps"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker logs [Container ID]</span><br></pre></td></tr></table></figure><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/9/48ca91b490a2ba90bd5e45b10d1d482e.png" alt="docker logs"></p><p>出现 “Application startup complete.” 即代表程序已经就绪</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker attach [Container ID]</span><br></pre></td></tr></table></figure><p>attach 进入 docker 可以看到当前任务实时的生成进度</p><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/9/a638dc19dc2c7db1ff0451e51b5a5bcb.png" alt="docker attach"></p><h4 id="10-3-请求-API"><a href="#10-3-请求-API" class="headerlink" title="10.3 请求 API"></a>10.3 请求 API</h4><p>参考代码，具体参照 leak 的前端后端项目，以及其中的 sd-private\hydra-node-http\main.py</p><p>prompt 中 masterpiece, best quality, 开头对应原版 web Add Quality Tags 选项，不建议删除，后面直接跟自己 prompt 即可</p><p>uc 部分对应 web Undesired Content，建议保留默认</p><p>sampler 是采样方法，可选plms/ddim/k_euler/k_euler_ancestral/k_heun/k_dpm_2/k_dpm_2_ancestral/k_lms</p><p>seed 是种子，自己随机一个整数数字，不然一直会出一样的结果。</p><p>n_samples 代表要生成几张图片</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import json</span><br><span class="line">import base64</span><br><span class="line">import random</span><br><span class="line"></span><br><span class="line">endpoint = "http://10.10.12.67/generate"</span><br><span class="line"></span><br><span class="line">data = {"prompt": "masterpiece, best quality, brown red hair,blue eyes,twin tails,holding cat", "seed": random.randint(0, 2**32)</span><br><span class="line">,"n_samples":1,"sampler":"ddim","width":512,"height":768,"scale":11,"steps":28,"uc":"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry"}</span><br><span class="line">req = requests.post(endpoint, json=data).json()</span><br><span class="line">output = req["output"]</span><br><span class="line">for x in output:</span><br><span class="line">  img = base64.b64decode(x)</span><br><span class="line">  with open("output-" + str(output.index(x)) + ".png", "wb") as f:</span><br><span class="line">    f.write(img)</span><br></pre></td></tr></table></figure><h4 id="生成的效果图示例"><a href="#生成的效果图示例" class="headerlink" title="生成的效果图示例"></a>生成的效果图示例</h4><blockquote><p>Genshin,lumine, gold hair, cat, girl,White silk</p></blockquote><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/9/7aaba36e0abb9677e1d11c4c7548fa62.png" alt="Genshin,lumine, gold hair, cat, girl,White silk"></p><p></p></details><h3 id="11-创建一个-Docker-Bridge"><a href="#11-创建一个-Docker-Bridge" class="headerlink" title="11. 创建一个 Docker Bridge"></a>11. 创建一个 Docker Bridge</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network create --subnet=10.240.0.0/16 nainetwork</span><br></pre></td></tr></table></figure><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/10/be4319b621364f286163f662bd815f64.png" alt="创建docker bridge"></p><h3 id="12-下载-Tag-Predict-所需文件"><a href="#12-下载-Tag-Predict-所需文件" class="headerlink" title="12. 下载 Tag Predict 所需文件"></a>12. 下载 Tag Predict 所需文件</h3><p><a target="_blank" rel="noopener" href="https://pan.lumine233.ml/d/Lumine/NovelAI-Leak/TagPredict/safe.zip">https://pan.lumine233.ml/d/Lumine/NovelAI-Leak/TagPredict/safe.zip</a></p><h3 id="13-将上一步的压缩包解压到Novelai-文件夹中。"><a href="#13-将上一步的压缩包解压到Novelai-文件夹中。" class="headerlink" title="13. 将上一步的压缩包解压到Novelai 文件夹中。"></a>13. 将上一步的压缩包解压到Novelai 文件夹中。</h3><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/10/a79b0a38f22f10ff1f040a31476740f4.png" alt="unzip"></p><h3 id="14-修改-Docker-中的-models-py-文件让他从本地加载-Tag-Predict-依赖文件"><a href="#14-修改-Docker-中的-models-py-文件让他从本地加载-Tag-Predict-依赖文件" class="headerlink" title="14. 修改 Docker 中的 models.py 文件让他从本地加载 Tag Predict 依赖文件"></a>14. 修改 Docker 中的 models.py 文件让他从本地加载 Tag Predict 依赖文件</h3><p>执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd ~</span><br><span class="line"></span><br><span class="line">mkdir docker</span><br><span class="line"></span><br><span class="line">cd docker</span><br></pre></td></tr></table></figure><p>下载 models.py</p><p><a target="_blank" rel="noopener" href="https://pan.lumine233.ml/d/Lumine/NovelAI-Leak/Models/models.py">https://pan.lumine233.ml/d/Lumine/NovelAI-Leak/Models/models.py</a></p><p>然后将 models.py 下载并存放到新建的 docker 文件夹内</p><p>执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo -e "FROM novelai:latest\nCOPY models.py /usr/src/app/hydra_node" &gt; Dockerfile</span><br></pre></td></tr></table></figure><p>检查一下文件夹内容</p><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/10/ff8ac1de29a44da5acbc05b26b6c109d.png" alt="内容"></p><p>无误的话执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build . -t novelai:latest</span><br></pre></td></tr></table></figure><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/10/92f00e29bd87dc06f736b39e5374f05d.png" alt="build"></p><h3 id="15-启动-Tag-Predict-Docker"><a href="#15-启动-Tag-Predict-Docker" class="headerlink" title="15. 启动 Tag Predict Docker"></a>15. 启动 Tag Predict Docker</h3><blockquote><p>注意：他可能需要从被墙的 Huggingface 下载东西，建议机器科学上网</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --gpus all --network "nainetwork" --name "tag-predict" --restart=always -d -p 127.0.0.1:7000:7000 -v 上文中解压 Novelai 相关文件的位置:/root -e DTYPE="float32" -e AMP="1" -e MODEL="embedder" -e DEV="True" -e MODEL_PATH="/root/stableckpt/animefull-latest" -e MODULE_PATH="/root/stableckpt/modules" -e TRANSFORMERS_CACHE="/root/transformer_cache" -e SENTRY_URL=""-e ENABLE_EMA="1"-e VAE_PATH="/root/stableckpt/animevae.pt"-e BASEDFORMER="1"-e PENULTIMATE="1" -e TOKEN=114514qwqqwq novelai:latest gunicorn main:app --workers 1 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:7000</span><br></pre></td></tr></table></figure><h3 id="16-查看-Tag-Predict-Docker-状态"><a href="#16-查看-Tag-Predict-Docker-状态" class="headerlink" title="16. 查看 Tag Predict Docker 状态"></a>16. 查看 Tag Predict Docker 状态</h3><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/10/df47809d27357894e8c4003cd77125d5.png" alt="tag predict docker"></p><h3 id="17-测试-Tag-Predict-是否工作"><a href="#17-测试-Tag-Predict-是否工作" class="headerlink" title="17. 测试 Tag Predict 是否工作"></a>17. 测试 Tag Predict 是否工作</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl 'http://127.0.0.1:7000/predict-tags' -H 'Authorization: Bearer 114514qwqqwq' -H 'Content-Type: application/json' --data-raw '{"prompt":"kochiya"}'</span><br></pre></td></tr></table></figure><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/10/f2b03cec40e3a3023ec7f08643d6b92a.png" alt="tag predict"></p><blockquote><p><strong>如果以上步骤一切正常的话，就可以开始部署 web 的后端了</strong></p></blockquote><h3 id="18-运行-Pgsql"><a href="#18-运行-Pgsql" class="headerlink" title="18. 运行 Pgsql"></a>18. 运行 Pgsql</h3><h4 id="18-1-下载-Pgsql-数据库文件"><a href="#18-1-下载-Pgsql-数据库文件" class="headerlink" title="18.1 下载 Pgsql 数据库文件"></a>18.1 下载 Pgsql 数据库文件</h4><p><a target="_blank" rel="noopener" href="https://pan.lumine233.ml/d/Lumine/NovelAI-Leak/Pgsql/pgsqldata.tar.gz">https://pan.lumine233.ml/d/Lumine/NovelAI-Leak/Pgsql/pgsqldata.tar.gz</a></p><h4 id="18-2-解压-Pgsql-数据库文件"><a href="#18-2-解压-Pgsql-数据库文件" class="headerlink" title="18.2 解压 Pgsql 数据库文件"></a>18.2 解压 Pgsql 数据库文件</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf pgsqldata.tar.gz</span><br></pre></td></tr></table></figure><h4 id="18-3-拉取-Pgsql-Docker"><a href="#18-3-拉取-Pgsql-Docker" class="headerlink" title="18.3 拉取 Pgsql Docker"></a>18.3 拉取 Pgsql Docker</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull postgres</span><br></pre></td></tr></table></figure><h4 id="18-4运行-Pgsql"><a href="#18-4运行-Pgsql" class="headerlink" title="18.4运行 Pgsql"></a>18.4运行 Pgsql</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --network "nainetwork" --name "pgsql" -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=development -v 解压出的 Pgsqldata 文件夹位置:/var/lib/postgresql/data postgres</span><br></pre></td></tr></table></figure><h3 id="19-运行-Web-后端"><a href="#19-运行-Web-后端" class="headerlink" title="19. 运行 Web 后端"></a>19. 运行 Web 后端</h3><p>下载并导入 Web 后端 Docker</p><h4 id="19-1-导入-Docker"><a href="#19-1-导入-Docker" class="headerlink" title="19.1 导入 Docker"></a>19.1 导入 Docker</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker load -i novelai-backend.tar</span><br></pre></td></tr></table></figure><h4 id="19-2-运行-Docker"><a href="#19-2-运行-Docker" class="headerlink" title="19.2 运行 Docker"></a>19.2 运行 Docker</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --log-opt max-size=10m --log-opt max-file=3 --network "nainetwork" --restart=always -p 3000:3000 -e LISTEN_ADDRESS=0.0.0.0 -e VOICE_TOKEN=114514qwqqwq -e NODE_ENV=development -e DB_HOST=pgsql -e DB_PORT=5432 -e DB_USER=postgres -e DB_PASSWORD=development -e DB_NAME=novelai -e RECAPTCHA_SECRET_KEY=disabled -e HYDRA_DUMMY=true -e AI_KEY= -e JWT_SIGN_SECRET=b95bac5a-9c43-4cdf-8c65-fc1bcc557e41 -e PADDLE_VENDOR_ID=1234 -e PADDLE_VENDOR_TOKEN= -e MAILGUN_DOMAIN=1234 -e MAILGUN_KEY=1234 -e REGISTRATION_DISABLED= -e ADMIN_PASSWORD=1234 novelai-backend:latest</span><br></pre></td></tr></table></figure><p>检查 Web 后端 Log</p><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/10/52c7f89e46d035d541d8d6d1533dc2bc.png" alt="Log"></p><h3 id="20-运行模型"><a href="#20-运行模型" class="headerlink" title="20. 运行模型"></a>20. 运行模型</h3><blockquote><p>如果准备同时加载两个模型的话对显存要求比较高，量力而行。</p></blockquote><h4 id="20-1-加载-Curated-模型"><a href="#20-1-加载-Curated-模型" class="headerlink" title="20.1 加载 Curated 模型"></a>20.1 加载 Curated 模型</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --gpus all -d  --restart=always --network "nainetwork" --name "nai-sfw" -v 解压的 NovelAI 文件夹位置:/root -e DTYPE="float16" -e CLIP_CONTEXTS=3  -e AMP="1" -e MODEL="stable-diffusion" -e DEV="True" -e MODEL_PATH="/root/stableckpt/animesfw-latest" -e MODULE_PATH="/root/stableckpt/modules" -e TRANSFORMERS_CACHE="/root/transformer_cache" -e SENTRY_URL=""-e ENABLE_EMA="1"-e VAE_PATH="/root/stableckpt/animevae.pt"-e BASEDFORMER="1"-e PENULTIMATE="1" -e TOKEN=114514qwqqwq novelai:latest gunicorn main:app --workers 1 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:80</span><br></pre></td></tr></table></figure><h4 id="20-2-加载-Full-模型"><a href="#20-2-加载-Full-模型" class="headerlink" title="20.2 加载 Full 模型"></a>20.2 加载 Full 模型</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --gpus all -d  --restart=always --network "nainetwork" --name "nai-full" -v 解压的 NovelAI 文件夹位置:/root -e DTYPE="float16" -e CLIP_CONTEXTS=3  -e AMP="1" -e MODEL="stable-diffusion" -e DEV="True" -e MODEL_PATH="/root/stableckpt/animefull-latest" -e MODULE_PATH="/root/stableckpt/modules" -e TRANSFORMERS_CACHE="/root/transformer_cache" -e SENTRY_URL=""-e ENABLE_EMA="1"-e VAE_PATH="/root/stableckpt/animevae.pt"-e BASEDFORMER="1"-e PENULTIMATE="1" -e TOKEN=114514qwqqwq novelai:latest gunicorn main:app --workers 1 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:80</span><br></pre></td></tr></table></figure><h3 id="21-部署前端"><a href="#21-部署前端" class="headerlink" title="21. 部署前端"></a>21. 部署前端</h3><h4 id="21-1-拉取-Nginx-docker"><a href="#21-1-拉取-Nginx-docker" class="headerlink" title="21.1 拉取 Nginx docker"></a>21.1 拉取 Nginx docker</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull nginx</span><br></pre></td></tr></table></figure><h4 id="21-2-下载前端文件"><a href="#21-2-下载前端文件" class="headerlink" title="21.2 下载前端文件"></a>21.2 下载前端文件</h4><p><a target="_blank" rel="noopener" href="https://pan.lumine233.ml/d/Lumine/NovelAI-Leak/Front-End/nginx.zip">https://pan.lumine233.ml/d/Lumine/NovelAI-Leak/Front-End/nginx.zip</a></p><h4 id="21-3-解压文件"><a href="#21-3-解压文件" class="headerlink" title="21.3 解压文件"></a>21.3 解压文件</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unzip nginx.zip</span><br></pre></td></tr></table></figure><h4 id="21-4启动-Nginx"><a href="#21-4启动-Nginx" class="headerlink" title="21.4启动 Nginx"></a>21.4启动 Nginx</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --network "nainetwork" -v 解压出来的 nginx 目录位置  /conf.d:/etc/nginx/conf.d -v 解压出来的 nginx 目录位置 /build:/etc/nginx/build -p 80:80 nginx:latest</span><br></pre></td></tr></table></figure><h3 id="22-修改-Hosts"><a href="#22-修改-Hosts" class="headerlink" title="22. 修改 Hosts"></a>22. 修改 Hosts</h3><p>将本地 Hosts 中添加一条</p><p>你后端部署在的机器的 ip novelai.baidu.com</p><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/10/d673c76704189b133079911ac2f00e42.png" alt="HOST"></p><h3 id="23-访问-Web"><a href="#23-访问-Web" class="headerlink" title="23. 访问 Web"></a>23. 访问 Web</h3><p>现在尝试访问一下 <a target="_blank" rel="external nofollow noopener noreferrer" href="http://novelai.baidu.com/">http://novelai.baidu.com</a></p><p>使用账号 <code>test@nya.la</code> 密码 <code>Aa123123123</code> 登录即可</p><p>只有 Image Generation 下面的功能是可以使用的。</p><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/10/d38cc6d9a02a4e0b23e40e8baed053ab.png" alt="WEB"></p><hr><h3 id="一些其他信息"><a href="#一些其他信息" class="headerlink" title="一些其他信息"></a>一些其他信息</h3><p>跑生成时的显存占用</p><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/10/0070748753b69a660cf7752278ffc280.png" alt="smi"></p><p>已知问题：</p><p>生成一个图片之后这破程序不回收显存，生成下一张就会</p><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/10/ab77799fc975b89722fee2d11e1b3544.png" alt="BOOM"></p><p>然后 docker 就会自动崩溃重启。</p><p>24G 显存的 A10 使用 img2img 功能，哪怕全默认配置</p><p><img src="https://static.lumine233.ml/Pic/load.png" data-src="https://static.lumine233.ml/Img/2022/10/10/f7aefb17160576d224d761c650ef1086.png" alt="BOOM"></p><p>显存也不够他吃的</p></div><div class="post-copyright"><div class="post-copyright-icon"></div><div class="post-copyright-author"><span class="post-copyright-meta">作者: </span><span class="post-copyright-info"><a target="_blank" rel="external nofollow noopener noreferrer" href="https://telegra.ph/NovelAI-%E5%8E%9F%E7%89%88%E7%BD%91%E9%A1%B5UI%E5%90%8E%E7%AB%AF%E9%83%A8%E7%BD%B2%E6%95%99%E7%A8%8B-10-10">Sanae</a></span></div><div class="post-copyright-type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://blog.lumine233.ml/article/NovelAI-Leak.html">https://blog.lumine233.ml/article/NovelAI-Leak.html</a></span></div><div class="post-copyright-notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本文章采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external nofollow noopener noreferrer">CC BY-NC-SA 4.0</a> 许可协议。来源 <a href="https://blog.lumine233.ml/" target="_blank">Telegram</a></span></div></div><div class="pagination-post"><a href="/article/Fix-Google-Account-Unverifiable.html"><div class="next-title">关于我是如何修复谷歌账户手机号无法验证的问题的<i class="fas fa-chevron-right"></i></div><div class="next-desc">最近我在注册一个新的Google账户的时候 碰到了此电话号码无法用于验证的问题 也尝试过网络上的解决方案 比如更改浏览器语言什么的 但是还是提示无法验证</div></a></div><div class="comment-head" id="直达评论"><hr><div class="comment-headline"><i class="fas fa-comments fa-fw"></i> <span>评论</span></div><div id="tcomment"></div><script>function LoadTwikoo(){mengd.getScript("https://cdn.jsdelivr.net/npm/twikoo@1.6.7/dist/twikoo.all.min.js",function(){twikoo.init(Object.assign({el:"#tcomment",envId:"https://api-chat.lumine233.ml/",region:"",path:location.pathname},{source:"https://cdn.jsdelivr.net/npm/twikoo@1.6.7/dist/twikoo.all.min.js",envId:"https://api-chat.lumine233.ml/"}))})}LoadTwikoo()</script></div></article><div id="toc-wrap"><div id="toc"><div class="toc-title"><div>目录 <span class="num">0%</span></div><progress class="progress" value="0" max="100"></progress></div><div class="toc-list"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%87%86%E5%A4%87"><span class="toc-text">1. 准备</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A1%AC%E4%BB%B6%E9%9C%80%E6%B1%82%EF%BC%9A"><span class="toc-text">硬件需求：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%AE%89%E8%A3%85-Docker"><span class="toc-text">2. 安装 Docker</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%AE%89%E8%A3%85-Nvidia-Container-Toolkit"><span class="toc-text">3. 安装 Nvidia-Container-Toolkit</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Ubuntu-Debian%EF%BC%9A"><span class="toc-text">Ubuntu, Debian：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#CentOS-x2F-RHEL"><span class="toc-text">CentOS/RHEL</span></a></li></ol></li></ol><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%AE%89%E8%A3%85%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8"><span class="toc-text">4. 安装显卡驱动</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E7%A1%AE%E8%AE%A4%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8%E5%B7%B2%E7%BB%8F%E5%AE%89%E8%A3%85%E5%A5%BD-%E5%B9%B6%E4%B8%94nvidia-smi%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E6%98%BE%E5%8D%A1"><span class="toc-text">5. 确认显卡驱动已经安装好,并且nvidia-smi可以看到显卡</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E7%A1%AE%E8%AE%A4-Nvidia-Container-Toolkit-%E5%AE%89%E8%A3%85%E6%88%90%E5%8A%9F"><span class="toc-text">6. 确认 Nvidia-Container-Toolkit 安装成功</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E4%B8%8B%E8%BD%BD-NovelAI-%E6%A8%A1%E5%9E%8B%E7%9B%B8%E5%85%B3%E6%96%87%E4%BB%B6"><span class="toc-text">7. 下载 NovelAI 模型相关文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-%E8%A7%A3%E5%8E%8B-NovelAI-%E6%A8%A1%E5%9E%8B%E7%9B%B8%E5%85%B3%E6%96%87%E4%BB%B6"><span class="toc-text">8. 解压 NovelAI 模型相关文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-%E4%B8%8B%E8%BD%BD-Docker-%E9%95%9C%E5%83%8F%E7%9B%B8%E5%85%B3%E6%96%87%E4%BB%B6"><span class="toc-text">9. 下载 Docker 镜像相关文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-%E5%AF%BC%E5%85%A5-Docker-%E9%95%9C%E5%83%8F"><span class="toc-text">10. 导入 Docker 镜像</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#10-1-%E8%BF%90%E8%A1%8C-Docker"><span class="toc-text">10.1 运行 Docker</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-2-%E6%9F%A5%E7%9C%8B%E5%AE%B9%E5%99%A8%E7%8A%B6%E6%80%81"><span class="toc-text">10.2 查看容器状态</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-3-%E8%AF%B7%E6%B1%82-API"><span class="toc-text">10.3 请求 API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E7%9A%84%E6%95%88%E6%9E%9C%E5%9B%BE%E7%A4%BA%E4%BE%8B"><span class="toc-text">生成的效果图示例</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA-Docker-Bridge"><span class="toc-text">11. 创建一个 Docker Bridge</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-%E4%B8%8B%E8%BD%BD-Tag-Predict-%E6%89%80%E9%9C%80%E6%96%87%E4%BB%B6"><span class="toc-text">12. 下载 Tag Predict 所需文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-%E5%B0%86%E4%B8%8A%E4%B8%80%E6%AD%A5%E7%9A%84%E5%8E%8B%E7%BC%A9%E5%8C%85%E8%A7%A3%E5%8E%8B%E5%88%B0Novelai-%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%AD%E3%80%82"><span class="toc-text">13. 将上一步的压缩包解压到Novelai 文件夹中。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#14-%E4%BF%AE%E6%94%B9-Docker-%E4%B8%AD%E7%9A%84-models-py-%E6%96%87%E4%BB%B6%E8%AE%A9%E4%BB%96%E4%BB%8E%E6%9C%AC%E5%9C%B0%E5%8A%A0%E8%BD%BD-Tag-Predict-%E4%BE%9D%E8%B5%96%E6%96%87%E4%BB%B6"><span class="toc-text">14. 修改 Docker 中的 models.py 文件让他从本地加载 Tag Predict 依赖文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-%E5%90%AF%E5%8A%A8-Tag-Predict-Docker"><span class="toc-text">15. 启动 Tag Predict Docker</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#16-%E6%9F%A5%E7%9C%8B-Tag-Predict-Docker-%E7%8A%B6%E6%80%81"><span class="toc-text">16. 查看 Tag Predict Docker 状态</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-%E6%B5%8B%E8%AF%95-Tag-Predict-%E6%98%AF%E5%90%A6%E5%B7%A5%E4%BD%9C"><span class="toc-text">17. 测试 Tag Predict 是否工作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#18-%E8%BF%90%E8%A1%8C-Pgsql"><span class="toc-text">18. 运行 Pgsql</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#18-1-%E4%B8%8B%E8%BD%BD-Pgsql-%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6"><span class="toc-text">18.1 下载 Pgsql 数据库文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#18-2-%E8%A7%A3%E5%8E%8B-Pgsql-%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6"><span class="toc-text">18.2 解压 Pgsql 数据库文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#18-3-%E6%8B%89%E5%8F%96-Pgsql-Docker"><span class="toc-text">18.3 拉取 Pgsql Docker</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#18-4%E8%BF%90%E8%A1%8C-Pgsql"><span class="toc-text">18.4运行 Pgsql</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#19-%E8%BF%90%E8%A1%8C-Web-%E5%90%8E%E7%AB%AF"><span class="toc-text">19. 运行 Web 后端</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#19-1-%E5%AF%BC%E5%85%A5-Docker"><span class="toc-text">19.1 导入 Docker</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#19-2-%E8%BF%90%E8%A1%8C-Docker"><span class="toc-text">19.2 运行 Docker</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#20-%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%9E%8B"><span class="toc-text">20. 运行模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#20-1-%E5%8A%A0%E8%BD%BD-Curated-%E6%A8%A1%E5%9E%8B"><span class="toc-text">20.1 加载 Curated 模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#20-2-%E5%8A%A0%E8%BD%BD-Full-%E6%A8%A1%E5%9E%8B"><span class="toc-text">20.2 加载 Full 模型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#21-%E9%83%A8%E7%BD%B2%E5%89%8D%E7%AB%AF"><span class="toc-text">21. 部署前端</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#21-1-%E6%8B%89%E5%8F%96-Nginx-docker"><span class="toc-text">21.1 拉取 Nginx docker</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#21-2-%E4%B8%8B%E8%BD%BD%E5%89%8D%E7%AB%AF%E6%96%87%E4%BB%B6"><span class="toc-text">21.2 下载前端文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#21-3-%E8%A7%A3%E5%8E%8B%E6%96%87%E4%BB%B6"><span class="toc-text">21.3 解压文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#21-4%E5%90%AF%E5%8A%A8-Nginx"><span class="toc-text">21.4启动 Nginx</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-%E4%BF%AE%E6%94%B9-Hosts"><span class="toc-text">22. 修改 Hosts</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#23-%E8%AE%BF%E9%97%AE-Web"><span class="toc-text">23. 访问 Web</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E5%85%B6%E4%BB%96%E4%BF%A1%E6%81%AF"><span class="toc-text">一些其他信息</span></a></li></div></div></div></main></div><section id="rightside"><div class="rightside-item"><a id="open-toc" title="目录"><i class="fas fa-list-ul"></i> </a><a href="javascript:void(0);" id="darkmode" title="深色/浅色 "><i class="fas fa-moon"></i> </a><a href="#直达评论" title="直达评论"><i class="fas fa-comments"></i> </a><a href="#" title="回到顶部"><i class="fas fa-arrow-up"></i></a></div></section><footer class="footer" id="footer"><div class="copyright">© 2022 <i class="fas fa-fan"></i> Lumine'blog</div><div class="framework-info"><span>框架</span> <a href="https://hexo.io" target="_blank" rel="external nofollow noopener noreferrer">Hexo</a> <span class="footer-separator">|</span> <span>主题 </span><a href="https://github.com/lete114/hexo-theme-MengD" target="_blank" rel="external nofollow noopener noreferrer">MengD.(萌典)</a></div><div class="custom-text">「为了未来，不能沉湎在美梦当中。又或者说，为了让人们有沉湎在美梦当中的余裕，必须有人醒过来，面对黎明前的黑暗。」<br><time id="timedate"></time><script>const time=mengd.getDaysDiffBetweenDates("2022-7-28");document.getElementById("timedate").innerText=`小站于各种崩坏中续存了${time}天`</script><br><a target="_blank" rel="external nofollow noopener noreferrer" href="https://icp.gov.moe/?keyword=20222284">萌ICP备20222284号</a></div></footer><div id="mask" onclick="closeAll()"></div><div id="local-search"><div id="local-search-title">本地搜索</div><input id="local-search-input" autocomplete="off" placeholder="搜索文章" type="text"><hr><div id="local-search-result"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><script src="/js/search.js?v=a0523e259c"></script><script src="/js/main.js?v=e948cc69e9"></script><script>var titleTime,originTitle=document.title;document.addEventListener("visibilitychange",function(){document.hidden?(document.title="(つェ⊂) 我藏好了哦~ "+originTitle,clearTimeout(titleTime)):(document.title="(*´∇｀*) 被你发现啦~ "+originTitle,titleTime=setTimeout(function(){document.title=originTitle},2e3))})</script><script src="/js/lazyload.js?v=151b871c0e"></script><script>mengd.getScript("/third-party/js/prefetch-page.js?v=19a2c017da",()=>{const e=requestIdleCallback;e?e(()=>{prefetch({delay:1e3,threshold:25,customs:["/search.json?v=e844149e27"]})}):setTimeout(()=>{prefetch({delay:1e3,threshold:25,customs:["/search.json?v=e844149e27"]})},3e3)})</script></body></html>